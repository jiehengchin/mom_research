{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from binance_data_loader import BinanceDataLoader\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-loader",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = BinanceDataLoader(\n",
    "    data_directory=r\"C:\\Users\\USER\\Documents\\Binance_related\\dailytickerdata2020\",\n",
    "    min_records=30,\n",
    "    min_volume=1e5,\n",
    "    start_date=\"2022-01-01\",\n",
    "    end_date=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get price data\n",
    "df = data_loader.get_price_matrix()\n",
    "print(f\"Price data shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculate-returns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns\n",
    "rets = df.pct_change().fillna(0)\n",
    "print(f\"Returns data shape: {rets.shape}\")\n",
    "rets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "volatility-return-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility-Return Relationship Analysis\n",
    "# Select top volume assets for analysis (to avoid too many lines)\n",
    "volume_data = {}\n",
    "for ticker in data_loader.get_universe():\n",
    "    ticker_data = data_loader._crypto_universe[ticker]['data']\n",
    "    avg_volume = ticker_data['volume'].mean()\n",
    "    volume_data[ticker] = avg_volume\n",
    "\n",
    "# Get top 10 highest volume assets\n",
    "top_volume_assets = sorted(volume_data.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "selected_assets = [asset[0] for asset in top_volume_assets]\n",
    "print(f\"Analyzing top 10 volume assets: {selected_assets}\")\n",
    "\n",
    "# Filter dataframe to selected assets\n",
    "df_selected = df[selected_assets]\n",
    "rets_selected = rets[selected_assets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intercept-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot intercepts: Lag Return Vol vs Next Day Return\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "print(\"Calculating volatility-return relationships...\")\n",
    "for column in tqdm(df_selected.columns):\n",
    "    intercepts = []\n",
    "    slopes = []\n",
    "\n",
    "    for lag in range(2, 365):\n",
    "        try:\n",
    "            # Calculate rolling volatility\n",
    "            vol = rets_selected[1:][column].rolling(window=lag).std().iloc[lag:-1]\n",
    "            \n",
    "            # Calculate next day returns (forward-looking)\n",
    "            next_day_rets = df_selected[column].pct_change(-1)[lag+1:-1]\n",
    "            \n",
    "            # Ensure same length and remove NaN values\n",
    "            min_len = min(len(vol), len(next_day_rets))\n",
    "            vol_clean = vol.iloc[:min_len].dropna()\n",
    "            ret_clean = next_day_rets.iloc[:min_len].dropna()\n",
    "            \n",
    "            # Align indices\n",
    "            common_idx = vol_clean.index.intersection(ret_clean.index)\n",
    "            if len(common_idx) < 30:  # Need minimum observations\n",
    "                intercepts.append(np.nan)\n",
    "                slopes.append(np.nan)\n",
    "                continue\n",
    "                \n",
    "            vol_aligned = vol_clean[common_idx]\n",
    "            ret_aligned = ret_clean[common_idx]\n",
    "            \n",
    "            # Linear regression\n",
    "            reg = LinearRegression().fit(np.array(vol_aligned).reshape(-1,1), np.array(ret_aligned))\n",
    "            \n",
    "            intercepts.append(reg.intercept_)\n",
    "            slopes.append(reg.coef_[0])\n",
    "            \n",
    "        except Exception as e:\n",
    "            intercepts.append(np.nan)\n",
    "            slopes.append(np.nan)\n",
    "\n",
    "    # Plot intercepts\n",
    "    plt.plot(range(2, 365), intercepts, label=column, alpha=0.7)\n",
    "\n",
    "plt.axhline(0, color='r', linestyle='--', alpha=0.8)\n",
    "plt.title(\"Volatility-Return Relationship: Intercepts Across Different Lag Windows\")\n",
    "plt.xlabel(\"Volatility Calculation Window (days)\")\n",
    "plt.ylabel(\"Regression Intercept\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "slope-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot slopes: Volatility coefficient in predicting next-day returns\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "print(\"Plotting volatility coefficients...\")\n",
    "for column in tqdm(df_selected.columns):\n",
    "    intercepts = []\n",
    "    slopes = []\n",
    "\n",
    "    for lag in range(2, 365):\n",
    "        try:\n",
    "            # Calculate rolling volatility\n",
    "            vol = rets_selected[1:][column].rolling(window=lag).std().iloc[lag:-1]\n",
    "            \n",
    "            # Calculate next day returns (forward-looking)\n",
    "            next_day_rets = df_selected[column].pct_change(-1)[lag+1:-1]\n",
    "            \n",
    "            # Ensure same length and remove NaN values\n",
    "            min_len = min(len(vol), len(next_day_rets))\n",
    "            vol_clean = vol.iloc[:min_len].dropna()\n",
    "            ret_clean = next_day_rets.iloc[:min_len].dropna()\n",
    "            \n",
    "            # Align indices\n",
    "            common_idx = vol_clean.index.intersection(ret_clean.index)\n",
    "            if len(common_idx) < 30:  # Need minimum observations\n",
    "                intercepts.append(np.nan)\n",
    "                slopes.append(np.nan)\n",
    "                continue\n",
    "                \n",
    "            vol_aligned = vol_clean[common_idx]\n",
    "            ret_aligned = ret_clean[common_idx]\n",
    "            \n",
    "            # Linear regression\n",
    "            reg = LinearRegression().fit(np.array(vol_aligned).reshape(-1,1), np.array(ret_aligned))\n",
    "            \n",
    "            intercepts.append(reg.intercept_)\n",
    "            slopes.append(reg.coef_[0])\n",
    "            \n",
    "        except Exception as e:\n",
    "            intercepts.append(np.nan)\n",
    "            slopes.append(np.nan)\n",
    "\n",
    "    # Plot slopes\n",
    "    plt.plot(range(2, 365), slopes, label=column, alpha=0.7)\n",
    "\n",
    "plt.axhline(0, color='r', linestyle='--', alpha=0.8)\n",
    "plt.title(\"Volatility-Return Relationship: Slopes Across Different Lag Windows\")\n",
    "plt.xlabel(\"Volatility Calculation Window (days)\")\n",
    "plt.ylabel(\"Volatility Coefficient (Slope)\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for specific lag windows\n",
    "key_lags = [7, 14, 30, 60, 90, 180]  # Weekly, bi-weekly, monthly, etc.\n",
    "\n",
    "summary_results = []\n",
    "\n",
    "for lag in key_lags:\n",
    "    lag_results = {'lag': lag}\n",
    "    \n",
    "    for column in df_selected.columns[:5]:  # Top 5 assets only\n",
    "        try:\n",
    "            vol = rets_selected[1:][column].rolling(window=lag).std().iloc[lag:-1]\n",
    "            next_day_rets = df_selected[column].pct_change(-1)[lag+1:-1]\n",
    "            \n",
    "            min_len = min(len(vol), len(next_day_rets))\n",
    "            vol_clean = vol.iloc[:min_len].dropna()\n",
    "            ret_clean = next_day_rets.iloc[:min_len].dropna()\n",
    "            \n",
    "            common_idx = vol_clean.index.intersection(ret_clean.index)\n",
    "            if len(common_idx) < 30:\n",
    "                continue\n",
    "                \n",
    "            vol_aligned = vol_clean[common_idx]\n",
    "            ret_aligned = ret_clean[common_idx]\n",
    "            \n",
    "            reg = LinearRegression().fit(np.array(vol_aligned).reshape(-1,1), np.array(ret_aligned))\n",
    "            \n",
    "            # Calculate R-squared\n",
    "            r_squared = reg.score(np.array(vol_aligned).reshape(-1,1), np.array(ret_aligned))\n",
    "            \n",
    "            lag_results[f'{column}_intercept'] = reg.intercept_\n",
    "            lag_results[f'{column}_slope'] = reg.coef_[0]\n",
    "            lag_results[f'{column}_r2'] = r_squared\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    summary_results.append(lag_results)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_results)\n",
    "print(\"\\nSummary of Volatility-Return Relationships at Key Lag Windows:\")\n",
    "print(summary_df.round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}